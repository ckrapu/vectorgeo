{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import constants as c\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.fs\n",
    "import io\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "with open('secrets.yml', 'r') as f:\n",
    "    secrets = yaml.safe_load(f)\n",
    "\n",
    "s3_fs = pyarrow.fs.S3FileSystem(region='us-east-1', \n",
    "                                access_key=secrets['aws_access_key_id'], \n",
    "                                secret_key=secrets['aws_secret_access_key'])\n",
    "\n",
    "\n",
    "s3 = boto3.client('s3', aws_access_key_id=secrets['aws_access_key_id'], aws_secret_access_key=secrets['aws_secret_access_key'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10000 records with 161 columns\n",
      "Found 23 classes in the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read into memory all files in bucket c.S3_BUCKET with prefix c.LC_VPATH \n",
    "# which are parquet files\n",
    "read_s3_pq = lambda path: pq.ParquetDataset(path, filesystem=s3_fs).read_pandas().to_pandas()\n",
    "file_urls = [f\"{c.S3_BUCKET}/{d['Key']}\" for d in s3.list_objects(Bucket=c.S3_BUCKET, Prefix=c.LC_VPATH)['Contents']]\n",
    "\n",
    "dfs = map(read_s3_pq, file_urls)\n",
    "\n",
    "# Concatenate all the dataframes into one\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for increment_df in tqdm(dfs):\n",
    "    df = pd.concat([df, increment_df])\n",
    "\n",
    "print(f\"Loaded {len(df)} records with {len(df.columns)} columns\")\n",
    "\n",
    "# Make sure all classes are represented\n",
    "n_classes = len(c.LC_LEGEND)\n",
    "n_sampled_classes = len(set([x.split('_')[2] for x in df.columns]))\n",
    "\n",
    "assert n_classes == n_sampled_classes, f\"Expected {n_classes} classes, but only found {n_sampled_classes} classes in the data\"\n",
    "print(f\"Found {n_sampled_classes} classes in the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toggle binary columns on or off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 161)\n"
     ]
    }
   ],
   "source": [
    "use_binary = False\n",
    "\n",
    "if not use_binary:\n",
    "    cols_kept = [c for c in df.columns if 'binary' not in c]\n",
    "    df = df[cols_kept]\n",
    "    \n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 7.3414\n",
      "Epoch 2/50, Loss: 3.5506\n",
      "Epoch 3/50, Loss: 2.8014\n",
      "Epoch 4/50, Loss: 2.5816\n",
      "Epoch 5/50, Loss: 2.4511\n",
      "Epoch 6/50, Loss: 2.3622\n",
      "Epoch 7/50, Loss: 2.2789\n",
      "Epoch 8/50, Loss: 2.2370\n",
      "Epoch 9/50, Loss: 2.1928\n",
      "Epoch 10/50, Loss: 2.1651\n",
      "Epoch 11/50, Loss: 2.1429\n",
      "Epoch 12/50, Loss: 2.1102\n",
      "Epoch 13/50, Loss: 2.1022\n",
      "Epoch 14/50, Loss: 2.0789\n",
      "Epoch 15/50, Loss: 2.0479\n",
      "Epoch 16/50, Loss: 2.0445\n",
      "Epoch 17/50, Loss: 2.0193\n",
      "Epoch 18/50, Loss: 2.0102\n",
      "Epoch 19/50, Loss: 1.9911\n",
      "Epoch 20/50, Loss: 1.9925\n",
      "Epoch 21/50, Loss: 1.9790\n",
      "Epoch 22/50, Loss: 1.9695\n",
      "Epoch 23/50, Loss: 1.9659\n",
      "Epoch 24/50, Loss: 1.9603\n",
      "Epoch 25/50, Loss: 1.9512\n",
      "Epoch 26/50, Loss: 1.9411\n",
      "Epoch 27/50, Loss: 1.9365\n",
      "Epoch 28/50, Loss: 1.9312\n",
      "Epoch 29/50, Loss: 1.9286\n",
      "Epoch 30/50, Loss: 1.9286\n",
      "Epoch 31/50, Loss: 1.9229\n",
      "Epoch 32/50, Loss: 1.9111\n",
      "Epoch 33/50, Loss: 1.9114\n",
      "Epoch 34/50, Loss: 1.9090\n",
      "Epoch 35/50, Loss: 1.8994\n",
      "Epoch 36/50, Loss: 1.8991\n",
      "Epoch 37/50, Loss: 1.8918\n",
      "Epoch 38/50, Loss: 1.8929\n",
      "Epoch 39/50, Loss: 1.8896\n",
      "Epoch 40/50, Loss: 1.8868\n",
      "Epoch 41/50, Loss: 1.8822\n",
      "Epoch 42/50, Loss: 1.8772\n",
      "Epoch 43/50, Loss: 1.8713\n",
      "Epoch 44/50, Loss: 1.8708\n",
      "Epoch 45/50, Loss: 1.8648\n",
      "Epoch 46/50, Loss: 1.8629\n",
      "Epoch 47/50, Loss: 1.8669\n",
      "Epoch 48/50, Loss: 1.8687\n",
      "Epoch 49/50, Loss: 1.8565\n",
      "Epoch 50/50, Loss: 1.8618\n"
     ]
    }
   ],
   "source": [
    "from layers import ResidualBlock\n",
    "\n",
    "class ResNetAutoencoder(nn.Module):\n",
    "    def __init__(self, D, hidden_units, num_layers, z_dim, is_softmax=None, n_classes=None):\n",
    "        super(ResNetAutoencoder, self).__init__()\n",
    "\n",
    "        self.is_softmax = is_softmax\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        assert num_layers >= 2, \"Number of layers should be at least 2 for an autoencoder.\"\n",
    "\n",
    "        # Encoder\n",
    "        layers = [ResidualBlock(D, hidden_units)]\n",
    "        for _ in range(num_layers - 2):  # -2 because first and last layers are manually added\n",
    "            layers.append(ResidualBlock(hidden_units, hidden_units))\n",
    "        layers.append(ResidualBlock(hidden_units, z_dim))\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "\n",
    "        # Decoder\n",
    "        layers = [ResidualBlock(z_dim, hidden_units)]\n",
    "        for _ in range(num_layers - 2):\n",
    "            layers.append(ResidualBlock(hidden_units, hidden_units))\n",
    "        layers.append(ResidualBlock(hidden_units, D))\n",
    "        self.decoder = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        logits = self.decoder(z)\n",
    "\n",
    "        if not isinstance(self.is_softmax, type(None)):\n",
    "    \n",
    "            # (n, d) from (n, d) to (n, k, d/k) where k is the\n",
    "            # number of and d/k is the number of classes, assumed\n",
    "            # to be the same for each group\n",
    "            reshaped = logits[:, self.is_softmax].reshape(-1, self.n_classes)\n",
    "\n",
    "            probs_grouped = torch.softmax(reshaped, dim=1)\n",
    "            # Flatten along last axis\n",
    "            probs_grouped = probs_grouped.reshape(-1, self.is_softmax.sum())\n",
    "            probs_ungrouped = torch.sigmoid(logits[:, ~self.is_softmax])\n",
    "            probs = torch.concatenate((probs_grouped, probs_ungrouped), dim=1)\n",
    "        else:\n",
    "            probs = torch.sigmoid(logits)\n",
    "            \n",
    "        return probs\n",
    "\n",
    "class ConvResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downsample=False):\n",
    "        super(ConvResidualBlock, self).__init__()\n",
    "        \n",
    "        stride = 2 if downsample else 1\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "\n",
    "        out += self.shortcut(identity)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, z_channels, \n",
    "                 K, linear_dims, downsample_blocks, non_downsample_blocks, H, W):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        encoder_layers = []\n",
    "\n",
    "        # Interleaving blocks\n",
    "        current_channels = in_channels\n",
    "        for i in range(max(downsample_blocks, non_downsample_blocks)):\n",
    "            if i < downsample_blocks:\n",
    "                encoder_layers.append(ConvResidualBlock(current_channels, hidden_channels, downsample=True))\n",
    "                current_channels = hidden_channels\n",
    "            \n",
    "            if i < non_downsample_blocks:\n",
    "                encoder_layers.append(ConvResidualBlock(current_channels, hidden_channels))\n",
    "\n",
    "        self.encoder_conv = nn.Sequential(*encoder_layers)\n",
    "        \n",
    "        # Bottleneck linear layers\n",
    "        self.encoder_linear = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(current_channels * H * W, z_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(z_channels, current_channels * H * W),\n",
    "            nn.Unflatten(1, (current_channels, H, W))\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        decoder_layers = []\n",
    "        \n",
    "        for i in range(max(downsample_blocks, non_downsample_blocks)):\n",
    "            if i < downsample_blocks:\n",
    "                decoder_layers.append(nn.Upsample(scale_factor=2, mode='nearest'))\n",
    "                decoder_layers.append(ConvResidualBlock(current_channels, hidden_channels))\n",
    "            \n",
    "            if i < non_downsample_blocks:\n",
    "                decoder_layers.append(ConvResidualBlock(current_channels, hidden_channels))\n",
    "\n",
    "        # Final convolution layer to produce a single channel with depth K\n",
    "        decoder_layers.append(nn.Conv2d(hidden_channels, K, kernel_size=1, stride=1, padding=0))\n",
    "\n",
    "        self.decoder = nn.Sequential(*decoder_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder_conv(x)\n",
    "        x = self.encoder_linear(x)\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        # Reshape to apply softmax across the depth of K to get the required categorical representation.\n",
    "        b, c, h, w = x.size()\n",
    "        x = x.view(b, c, -1)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        x = x.view(b, c, h, w)\n",
    "\n",
    "        return x\n",
    "        \n",
    "def custom_loss(recon_x, x, weights):\n",
    "    # Binary Cross Entropy Loss\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='none')  # no reduction to get per-element loss\n",
    "    weighted_BCE = BCE * weights\n",
    "    return weighted_BCE.mean()\n",
    "\n",
    "def train(model, dataloader, optimizer, device, weights):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x in dataloader:\n",
    "        x = x[0].float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_x = model(x)\n",
    "\n",
    "        loss = custom_loss(recon_x, x, weights)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "_, D = df.shape\n",
    "\n",
    "hidden_units = 32\n",
    "num_layers = 2\n",
    "z_dim = 8\n",
    "\n",
    "n_rings    = len(c.LC_K_RING_SETS)\n",
    "is_softmax = np.zeros(D, dtype=bool)\n",
    "is_softmax[0:c.LC_N_CLASSES * n_rings] = True\n",
    "\n",
    "model = ResNetAutoencoder(D, hidden_units, num_layers, z_dim, is_softmax=is_softmax, n_classes=n_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Train the model\n",
    "tensor = torch.tensor(df.values, dtype=torch.float32)\n",
    "\n",
    "weights = 1.0 \n",
    "weights /= (tensor.mean(dim=0) + 1e-8) # adding a small constant to avoid division by zero\n",
    "\n",
    "# Create a TensorDataset from tensor\n",
    "dataset = TensorDataset(tensor)\n",
    "\n",
    "# Define a DataLoader\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "num_epochs    = 50\n",
    "\n",
    "train_time_start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    loss = train(model, train_dataloader, optimizer, device, weights)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}')\n",
    "\n",
    "train_time_end = time.time()\n",
    "total_train_time = train_time_end - train_time_start\n",
    "\n",
    "model_str = str(model)\n",
    "\n",
    "x_eval    = df.iloc[0:1000].values\n",
    "x_hat     = model.forward(torch.Tensor(x_eval)).detach().numpy()\n",
    "data_mean = df.mean(axis=0).values\n",
    "\n",
    "l1_err = lambda x_hat, x_true: np.abs(x_hat - x_true).mean()\n",
    "model_error, benchmark_error = l1_err(x_hat, x_eval), l1_err(data_mean, x_eval)\n",
    "\n",
    "metadata_record = {\n",
    "    'num_epochs'     : num_epochs,\n",
    "    'batch_size'     : batch_size,\n",
    "    'hidden_units'   : hidden_units,\n",
    "    'num_layers'     : num_layers,\n",
    "    'z_dim'          : z_dim,\n",
    "    'final_loss'     : loss,\n",
    "    'model_str'      : model_str,\n",
    "    'num_params'     : sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
    "    'train_time'     : total_train_time,\n",
    "    'model_error'    : model_error,\n",
    "    'benchmark_error': benchmark_error\n",
    "\n",
    "}\n",
    "# Write to logs/ folder\n",
    "current_date_str = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "model_filename = f'model-resnet-ae-{current_date_str}.json'\n",
    "\n",
    "# Write model to file, then upload to s3 at c.MODELS_DIR\n",
    "buffer = io.BytesIO()\n",
    "torch.save(model, buffer)\n",
    "s3.put_object(Bucket=c.S3_BUCKET, Key=f'models/{model_filename}', Body=buffer.getvalue())\n",
    "log_path = os.path.join('logs', f'log_{current_date_str}.json')\n",
    "\n",
    "with open(log_path, 'w') as f:\n",
    "    json.dump(metadata_record, f)\n",
    "\n",
    "# Upload to s3\n",
    "s3.upload_file(log_path, c.S3_BUCKET, f'logs/{os.path.basename(log_path)}')\n",
    "os.remove(log_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize=(14, 5))\n",
    "\n",
    "plt.sca(axes[0])\n",
    "plt.imshow(torch.Tensor(df.iloc[0:200].values), vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.title(\"Ground truth\")\n",
    "\n",
    "plt.sca(axes[1])\n",
    "plt.imshow(x_hat, vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.title(\"Reconstructed\")\n",
    "\n",
    "plt.sca(axes[2])\n",
    "plt.imshow(np.abs(x_hat-x_eval), vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.title(\"L1 error\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(c.FIGURES_DIR, 'autoencoder-reconstruction.png'), dpi=500)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vg-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
