{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import constants as c\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import io\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from models import ResnetCAE\n",
    "from tqdm import tqdm\n",
    "from s3fs.core import S3FileSystem\n",
    "from tensorflow.keras import layers, Model\n",
    "from datetime import datetime\n",
    "\n",
    "with open('secrets.yml', 'r') as f:\n",
    "    secrets = yaml.safe_load(f)\n",
    "\n",
    "s3_boto = boto3.client('s3', aws_access_key_id=secrets['aws_access_key_id'], aws_secret_access_key=secrets['aws_secret_access_key'])\n",
    "bucket  = boto3.resource('s3', aws_access_key_id=secrets['aws_access_key_id'], aws_secret_access_key=secrets['aws_secret_access_key']).Bucket(c.S3_BUCKET)\n",
    "s3fs    = S3FileSystem(key=secrets['aws_access_key_id'], secret=secrets['aws_secret_access_key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 files; resulting stacked array has shape (9999, 1, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "read_s3_np = lambda key: np.load(s3fs.open('{}/{}'.format(c.S3_BUCKET, key)))\n",
    "keys = [d['Key'] for d in s3_boto.list_objects(Bucket=c.S3_BUCKET, Prefix=c.LC_VPATH)['Contents'] if d['Key'].endswith('.npy')]\n",
    "\n",
    "train_data_int = np.concatenate(list(map(read_s3_np, keys)))\n",
    "print(f\"Loaded {len(keys)} files; resulting stacked array has shape {train_data_int.shape}\")\n",
    "\n",
    "# Convert to one-hot\n",
    "# We don't preprocess as one-hot because the storage is way larger. \n",
    "N, C, H, W = train_data_int.shape\n",
    "train_data = np.zeros((N, c.LC_N_CLASSES, H, W))\n",
    "\n",
    "for i in range(c.LC_N_CLASSES):\n",
    "    train_data[:, i, :, :] = (train_data_int == i).squeeze().astype(int)\n",
    "\n",
    "# Swap second and fourth axis for Keras\n",
    "# compatibility\n",
    "train_data = np.swapaxes(train_data, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_76 (InputLayer)       [(None, 32, 32, 23)]      0         \n",
      "                                                                 \n",
      " resnet_cae_3 (ResnetCAE)    (None, 32, 32, 23)        77975     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77975 (304.59 KB)\n",
      "Trainable params: 77207 (301.59 KB)\n",
      "Non-trainable params: 768 (3.00 KB)\n",
      "_________________________________________________________________\n",
      "Model: \"model_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_76 (InputLayer)       [(None, 32, 32, 23)]      0         \n",
      "                                                                 \n",
      " resnet_cae_3 (ResnetCAE)    (None, 32, 32, 23)        77975     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77975 (304.59 KB)\n",
      "Trainable params: 77207 (301.59 KB)\n",
      "Non-trainable params: 768 (3.00 KB)\n",
      "_________________________________________________________________\n",
      "313/313 [==============================] - 103s 292ms/step - loss: 1.9579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x175bf06d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read args from config file\n",
    "config_path = \"configs/resnet.json\"\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "    input_shape = config['input_shape']\n",
    "    K = config['K']\n",
    "    z_dim = config['z_dim']\n",
    "    num_filters = config['num_filters']\n",
    "    n_linear = config['n_linear']\n",
    "\n",
    "inputs = layers.Input(shape=input_shape)\n",
    "autoencoder = ResnetCAE(input_shape, K, z_dim, num_filters, n_linear)\n",
    "outputs = autoencoder(inputs)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "model.summary()\n",
    "\n",
    "metadata = {\n",
    "    \"input_shape\": input_shape,\n",
    "    \"K\": K,\n",
    "    \"z_dim\": z_dim,\n",
    "    \"num_filters\": num_filters,\n",
    "    \"n_linear\": n_linear,\n",
    "    \"summary\": model.summary(),\n",
    "    \"loss\": \"categorical_crossentropy\",\n",
    "}\n",
    "# Form model ID as timestamp plus parameter count\n",
    "model_id = f\"{int(time.time())}-{len(model.weights)}\"\n",
    "\n",
    "model.fit(train_data, train_data, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form model ID as timestamp plus parameter count\n",
    "timestamp_formatted = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "model_id = f\"{timestamp_formatted}-{model.count_params()}p\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 90ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y6/0j8bg02j23nct6lpnhxhyb4r0000gr/T/ipykernel_64255/4151244415.py:10: RuntimeWarning: Mean of empty slice.\n",
      "  tjur_r2[i] = (x_true_class * x_pred_class).mean() - ((1-x_true_class) * x_pred_class).mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s3.Object(bucket_name='lql-data', key='models/metadata/metadata-2023-08-17-01-45-15-77975p.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tjur_r2 = {}\n",
    "x_true = train_data[0:100]\n",
    "x_pred = model.predict(x_true)\n",
    "\n",
    "x_true_int = np.argmax(x_true, axis=-1)\n",
    "for i in range(c.LC_N_CLASSES):\n",
    "    is_in_class = (x_true_int == i).any(axis=(1,2))\n",
    "    x_true_class = x_true[is_in_class]\n",
    "    x_pred_class = x_pred[is_in_class]\n",
    "    tjur_r2[i] = (x_true_class * x_pred_class).mean() - ((1-x_true_class) * x_pred_class).mean()\n",
    "\n",
    "metadata['tjur_r2_class'] = tjur_r2\n",
    "\n",
    "# Save metadata\n",
    "metadata_key = f\"models/metadata/metadata-{model_id}.json\"\n",
    "\n",
    "# Upload to S3\n",
    "bucket.put_object(Key=metadata_key, Body=json.dumps(metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 2, figsize=(10, 5*6))\n",
    "\n",
    "for i in range(6):\n",
    "    axes[i,0].imshow(np.argmax(x_true[i], axis=-1), cmap='tab20b')\n",
    "    axes[i,1].imshow(np.argmax(x_pred[i], axis=-1), cmap='tab20b')\n",
    "    axes[i,0].axis('off'), axes[i,1].axis('off')\n",
    "\n",
    "img_data = io.BytesIO()\n",
    "plt.savefig(img_data, format='png')\n",
    "img_data.seek(0)\n",
    "\n",
    "key = f'figures/reconstructions_{model_id}.png'\n",
    "bucket.put_object(Body=img_data, ContentType='image/png', Key=key)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vg-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
